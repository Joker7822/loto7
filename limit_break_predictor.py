#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
LimitBreakPredictor: æ—¢å­˜ã® LotoPredictor ã‚’å¼·åŒ–ã—ã€
- é€²åŒ–çš„ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ï¼ˆGAï¼‰
- æ¡ä»¶ä»˜ãï¼ˆåˆ¶ç´„ä»˜ãï¼‰ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ï¼ˆæ“¬ä¼¼çš„æ¡ä»¶ä»˜ãDiffusion/ç¢ºç‡çš„ç”Ÿæˆï¼‰
- å¤šç›®çš„ãƒ•ã‚£ãƒƒãƒˆãƒã‚¹ï¼ˆåˆ†å¸ƒæ•´åˆæ€§ãƒ»å¤šæ§˜æ€§ãƒ»ãƒ«ãƒ¼ãƒ«é©åˆåº¦ï¼‰
ã‚’çµ±åˆã—ã¦ "é™ç•Œçªç ´" ã—ãŸå€™è£œç”Ÿæˆã‚’è¡Œã†ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã€‚

ã€ä½¿ã„æ–¹ï¼ˆå˜ä½“å®Ÿè¡Œï¼‰ã€‘
$ python limit_break_predictor.py

ã€ä½¿ã„æ–¹ï¼ˆæ—¢å­˜ã‚³ãƒ¼ãƒ‰ã¨çµ±åˆï¼‰ã€‘
from limit_break_predictor import LimitBreakPredictor, ConstraintConfig
lbp = LimitBreakPredictor()
final_preds = lbp.limit_break_predict(latest_data_df, n_out=50)
# CSVä¿å­˜ï¼ˆæ¬¡å›ã®æŠ½ã›ã‚“æ—¥ã‚’æŒ‡å®šï¼‰
lbp.save_predictions(final_preds, drawing_date_str)

ä¾å­˜ï¼šlottery_prediction.py å†…ã® LotoPredictor / å„ç¨®ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ï¼ˆå­˜åœ¨ã™ã‚Œã°è‡ªå‹•ã§æ´»ç”¨ï¼‰
"""
from __future__ import annotations

import math
import random
import traceback
from dataclasses import dataclass
from typing import List, Tuple, Dict, Optional, Iterable

import numpy as np
import pandas as pd

# æ—¢å­˜å®Ÿè£…ã‹ã‚‰æ‹å€Ÿï¼ˆå­˜åœ¨ã—ãªã„å ´åˆã¯å®‰å…¨ã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼‰
try:
    from lottery_prediction import (
        LotoPredictor,
        preprocess_data,
        create_advanced_features,
        save_predictions_to_csv,
        set_global_seed,
        get_latest_drawing_dates,
    )
except Exception:
    LotoPredictor = object  # type: ignore
    def preprocess_data(df):
        # æœ€ä½é™ã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
        nums = df["æœ¬æ•°å­—"].apply(lambda x: [int(v) for v in x] if isinstance(x, (list, tuple)) else [])
        X = pd.DataFrame({"mean": nums.apply(np.mean), "std": nums.apply(np.std)}).fillna(0.0).values
        return X, None, None
    def create_advanced_features(df):
        return df
    def save_predictions_to_csv(preds, drawing_date: str, filename: str = "loto7_predictions.csv"):
        row = {"æŠ½ã›ã‚“æ—¥": drawing_date}
        for i, (nums, conf) in enumerate(preds[:5], 1):
            row[f"äºˆæ¸¬{i}"] = ", ".join(map(str, nums))
            row[f"ä¿¡é ¼åº¦{i}"] = round(float(conf), 3)
        pd.DataFrame([row]).to_csv(filename, index=False, encoding="utf-8-sig")
    def set_global_seed(seed: int = 42):
        random.seed(seed); np.random.seed(seed)

# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
# åˆ¶ç´„ï¼ˆæ¡ä»¶ï¼‰è¨­å®š
# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
@dataclass
class ConstraintConfig:
    # å¥‡æ•°ã®å€‹æ•°ãƒ¬ãƒ³ã‚¸ï¼ˆä¾‹ï¼š2ã€œ5ï¼‰
    odd_min: int = 2
    odd_max: int = 5
    # åˆè¨ˆå€¤ãƒ¬ãƒ³ã‚¸ï¼ˆä¾‹ï¼š100ã€œ150ï¼‰
    sum_min: int = 100
    sum_max: int = 150
    # æœ€å°é–“éš”ï¼ˆéš£ã‚Šåˆã†å·®ï¼‰
    min_gap: int = 2
    # æ•°å­—ã®ãƒ¬ãƒ³ã‚¸ï¼ˆmax - min ãŒã“ã®å€¤ä»¥ä¸Šï¼‰
    min_range: int = 15
    # 1..37 ã®ç¯„å›²å¼·åˆ¶
    low: int = 1
    high: int = 37

# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
# ãƒ˜ãƒ«ãƒ‘ãƒ¼
# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
NumberSet = List[int]
PredWithScore = Tuple[NumberSet, float]


def _ensure_valid(numbers: Iterable[int], low: int = 1, high: int = 37) -> NumberSet:
    s = sorted(set(int(n) for n in numbers if low <= int(n) <= high))
    # è¶³ã‚Šãªã‘ã‚Œã°ãƒ©ãƒ³ãƒ€ãƒ è£œå®Œ
    while len(s) < 7:
        c = random.randint(low, high)
        if c not in s:
            s.append(c)
    return sorted(s[:7])


def _odd_count(nums: NumberSet) -> int:
    return sum(1 for n in nums if n % 2 != 0)


def _min_gap(nums: NumberSet) -> int:
    nums = sorted(nums)
    if len(nums) < 2:
        return 0
    return min(nums[i + 1] - nums[i] for i in range(len(nums) - 1))


def _range(nums: NumberSet) -> int:
    return max(nums) - min(nums)


def _within(v: float, lo: float, hi: float) -> float:
    """ç¯„å›²å†…ãªã‚‰1.0ã€é€¸è„±ã«å¿œã˜ã¦0ã¸ç·šå½¢æ¸›è¡°ï¼ˆã‚¯ãƒ©ãƒ³ãƒ—ï¼‰ã€‚"""
    if lo <= v <= hi:
        return 1.0
    d = min(abs(v - lo), abs(v - hi))
    width = max(1e-6, hi - lo)
    return max(0.0, 1.0 - d / width)


def constraint_score(nums: NumberSet, cfg: ConstraintConfig) -> float:
    """0ã€œ1ï¼ˆé«˜ã„ã»ã©è‰¯ã„ï¼‰"""
    oc = _odd_count(nums)
    total = sum(nums)
    mg = _min_gap(nums)
    rg = _range(nums)
    s = 0.25 * _within(oc, cfg.odd_min, cfg.odd_max)
    s += 0.35 * _within(total, cfg.sum_min, cfg.sum_max)
    s += 0.20 * _within(mg, cfg.min_gap, 37)
    s += 0.20 * _within(rg, cfg.min_range, 37)
    return float(s)


def number_frequencies(historical_df: pd.DataFrame) -> Dict[int, float]:
    counts = {i: 0 for i in range(1, 38)}
    if "æœ¬æ•°å­—" not in historical_df.columns:
        return counts
    for row in historical_df["æœ¬æ•°å­—"]:
        if isinstance(row, (list, tuple)):
            for n in row:
                if 1 <= int(n) <= 37:
                    counts[int(n)] += 1
    total = sum(counts.values()) or 1
    return {k: v / total for k, v in counts.items()}


def pair_triple_frequencies(historical_df: pd.DataFrame) -> Tuple[Dict[Tuple[int, int], int], Dict[Tuple[int, int, int], int]]:
    pair_freq: Dict[Tuple[int, int], int] = {}
    triple_freq: Dict[Tuple[int, int, int], int] = {}
    if "æœ¬æ•°å­—" not in historical_df.columns:
        return pair_freq, triple_freq
    for nums in historical_df["æœ¬æ•°å­—"]:
        if not isinstance(nums, (list, tuple)):
            continue
        s = sorted(int(x) for x in nums)
        # ãƒšã‚¢
        for i in range(len(s)):
            for j in range(i + 1, len(s)):
                p = (s[i], s[j])
                pair_freq[p] = pair_freq.get(p, 0) + 1
        # ãƒˆãƒªãƒ—ãƒ«
        for i in range(len(s)):
            for j in range(i + 1, len(s)):
                for k in range(j + 1, len(s)):
                    t = (s[i], s[j], s[k])
                    triple_freq[t] = triple_freq.get(t, 0) + 1
    return pair_freq, triple_freq


def cooccurrence_score(nums: NumberSet, pair_freq, triple_freq) -> float:
    s = sorted(nums)
    # æ­£è¦åŒ–ç”¨ã«é©å½“ãªã‚¹ã‚±ãƒ¼ãƒ«
    pf_sum = 0
    tf_sum = 0
    for i in range(7):
        for j in range(i + 1, 7):
            pf_sum += pair_freq.get((s[i], s[j]), 0)
    for i in range(7):
        for j in range(i + 1, 7):
            for k in range(j + 1, 7):
                tf_sum += triple_freq.get((s[i], s[j], s[k]), 0)
    # å¯¾æ•°åœ§ç¸®ã—ã¦0ã€œ1ã«æŠ¼ã—è¾¼ã‚€ï¼ˆçµŒé¨“å‰‡ï¼‰
    return float(1.0 - math.exp(-0.002 * (pf_sum + 0.5 * tf_sum)))


def diversity_penalty(nums: NumberSet, others: List[NumberSet]) -> float:
    if not others:
        return 0.0
    inters = []
    s = set(nums)
    for o in others:
        inters.append(len(s & set(o)))
    avg_inter = sum(inters) / len(inters)
    # å…±é€šãŒå¤šã„ã»ã©ãƒšãƒŠãƒ«ãƒ†ã‚£ï¼ˆ0ã€œ1ã«ï¼‰
    return min(1.0, avg_inter / 7.0)


# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
# Evolutionary Searchï¼ˆGAï¼‰
# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
class EvolutionEngine:
    def __init__(self, cfg: ConstraintConfig, num_low: int = 1, num_high: int = 37):
        self.cfg = cfg
        self.low = num_low
        self.high = num_high

    def _fitness(
        self,
        cand: NumberSet,
        hist_df: pd.DataFrame,
        pair_freq,
        triple_freq,
        others: Optional[List[NumberSet]] = None,
    ) -> float:
        cscore = constraint_score(cand, self.cfg)
        co = cooccurrence_score(cand, pair_freq, triple_freq)
        div_pen = diversity_penalty(cand, others or [])
        # å¤šç›®çš„ï¼šåˆ¶ç´„ãƒ»å…±èµ·æ€§ã‚’æœ€å¤§åŒ–ã€é¡ä¼¼åº¦ãƒšãƒŠãƒ«ãƒ†ã‚£ã‚’æœ€å°åŒ–
        score = 0.55 * cscore + 0.45 * co - 0.25 * div_pen
        return float(score)

    def _crossover(self, a: NumberSet, b: NumberSet) -> NumberSet:
        # ãƒ©ãƒ³ãƒ€ãƒ ã«ä¸€éƒ¨ã‚’äº¤å‰ï¼ˆ3ã€œ4å€‹ã‚’Aã‹ã‚‰ã€æ®‹ã‚Šã‚’Bã‹ã‚‰ï¼‰
        k = random.randint(3, 4)
        part = set(random.sample(a, k))
        child = list(part)
        for x in b:
            if len(child) >= 7:
                break
            if x not in part:
                child.append(x)
        return _ensure_valid(child, self.low, self.high)

    def _mutate(self, x: NumberSet, num_freq: Dict[int, float]) -> NumberSet:
        y = x[:]
        m = random.randint(1, 2)
        for _ in range(m):
            idx = random.randrange(7)
            # é »åº¦ã«æ¯”ä¾‹ã—ã¦ã‚µãƒ³ãƒ—ãƒ«ï¼ˆæ¢ç´¢ã®åã‚Šã‚’ä¸ãˆã‚‹ï¼‰
            pool = list(range(self.low, self.high + 1))
            weights = np.array([num_freq.get(i, 1e-6) for i in pool], dtype=float)
            if weights.sum() <= 0:
                cand = random.randint(self.low, self.high)
            else:
                weights = weights / weights.sum()
                cand = int(np.random.choice(pool, p=weights))
            y[idx] = cand
        return _ensure_valid(y, self.low, self.high)

    def search(
        self,
        seed_population: List[NumberSet],
        hist_df: pd.DataFrame,
        generations: int = 40,
        pop_size: int = 120,
        elite: int = 12,
    ) -> List[NumberSet]:
        """GA æ¤œç´¢ã€‚å„ä¸–ä»£ã§æ¯é›†å›£ã‚µã‚¤ã‚ºã‚’ä¸€å®šã«ä¿ã¤ã‚ˆã†ä¿®æ­£ã€‚ãƒˆãƒ¼ãƒŠãƒ¡ãƒ³ãƒˆã¯ç¾åœ¨ã®å€‹ä½“æ•°ã«åŸºã¥ãã€‚"""
        set_global_seed(777)
        elite = max(1, min(elite, pop_size - 1))
        num_freq = number_frequencies(hist_df)
        pair_freq, triple_freq = pair_triple_frequencies(hist_df)

        # åˆæœŸé›†å›£ï¼ˆä¸è¶³ã¯é »åº¦ã‚¬ã‚¤ãƒ‰ã®ãƒ©ãƒ³ãƒ€ãƒ ã§è£œã†ï¼‰
        pop: List[NumberSet] = []
        pop.extend(_ensure_valid(s) for s in seed_population)
        while len(pop) < pop_size:
            pool = list(range(self.low, self.high + 1))
            weights = np.array([num_freq.get(i, 1e-6) for i in pool], dtype=float)
            weights = weights / (weights.sum() or 1)
            cand = list(np.random.choice(pool, size=7, replace=False, p=weights)) if weights is not None else list(np.random.choice(pool, size=7, replace=False))
            pop.append(_ensure_valid(cand, self.low, self.high))
        # ä½™å‰°ãŒã‚ã‚Œã°åˆ‡ã‚Šè©°ã‚
        if len(pop) > pop_size:
            pop = pop[:pop_size]

        for _gen in range(generations):
            N = len(pop)
            # è©•ä¾¡
            scores = [self._fitness(ind, hist_df, pair_freq, triple_freq, others=pop) for ind in pop]

            # ã‚¨ãƒªãƒ¼ãƒˆé¸æŠ
            idxs = np.argsort(scores)[::-1]
            elites = [pop[i] for i in idxs[:elite]]

            # è¦ªé¸æŠï¼ˆç¾åœ¨ã®å€‹ä½“æ•° N ãƒ™ãƒ¼ã‚¹ï¼‰
            parents: List[NumberSet] = []
            target_children = pop_size - elite
            if N < 4:
                # å€‹ä½“ãŒå°‘ãªã„å ´åˆã¯ãƒ©ãƒ³ãƒ€ãƒ é¸æŠã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
                while len(parents) < target_children:
                    parents.append(random.choice(pop))
                    parents.append(random.choice(pop))
            else:
                while len(parents) < target_children:
                    t = random.sample(range(N), k=4)
                    best = max(t, key=lambda i: scores[i])
                    parents.append(pop[best])
                    # 2ä½“ç›®ã‚‚é¸ã‚“ã§äº¤å‰ã®å¤šæ§˜æ€§ã‚’ç¢ºä¿
                    t2 = random.sample(range(N), k=4)
                    best2 = max(t2, key=lambda i: scores[i])
                    parents.append(pop[best2])

            # äº¤å‰ï¼‹çªç„¶å¤‰ç•°ã§ target_children ä»¶ã®å­ã‚’ä½œã‚‹
            children: List[NumberSet] = []
            i = 0
            while len(children) < target_children:
                a = parents[i % len(parents)]
                b = parents[(i + 1) % len(parents)]
                child = self._crossover(a, b)
                if random.random() < 0.9:
                    child = self._mutate(child, num_freq)
                children.append(child)
                i += 2

            pop = elites + children
            # å¿µã®ãŸã‚ã‚µã‚¤ã‚ºã‚’å›ºå®š
            if len(pop) > pop_size:
                pop = pop[:pop_size]
            elif len(pop) < pop_size:
                # ãƒ©ãƒ³ãƒ€ãƒ è£œå……
                while len(pop) < pop_size:
                    pool = list(range(self.low, self.high + 1))
                    weights = np.array([num_freq.get(i, 1e-6) for i in pool], dtype=float)
                    weights = weights / (weights.sum() or 1)
                    cand = list(np.random.choice(pool, size=7, replace=False, p=weights)) if weights is not None else list(np.random.choice(pool, size=7, replace=False))
                    pop.append(_ensure_valid(cand, self.low, self.high))

        # æœ€çµ‚ã‚¹ã‚³ã‚¢ã§ã‚½ãƒ¼ãƒˆ
        final_scores = [self._fitness(ind, hist_df, pair_freq, triple_freq, others=[]) for ind in pop]
        order = np.argsort(final_scores)[::-1]
        return [pop[i] for i in order]


# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
# æ“¬ä¼¼ãƒ»æ¡ä»¶ä»˜ãã‚µãƒ³ãƒ—ãƒ©ãƒ¼ï¼ˆDiffusion/GAN ãŒã‚ã‚Œã°æ´»ç”¨ã€ãªã‘ã‚Œã°ç¢ºç‡ã‚µãƒ³ãƒ—ãƒ«ï¼‰
# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
class ConditionalSampler:
    def __init__(self, cfg: ConstraintConfig):
        self.cfg = cfg

    def sample_with_constraints(
        self,
        base_predictor: Optional[LotoPredictor],
        hist_df: pd.DataFrame,
        n_samples: int = 100,
        accept_threshold: float = 0.75,
    ) -> List[NumberSet]:
        out: List[NumberSet] = []
        freq = number_frequencies(hist_df)
        pool = np.arange(self.cfg.low, self.cfg.high + 1)
        weights = np.array([freq.get(int(i), 1e-6) for i in pool], dtype=float)
        # æ•°å€¤å®‰å®šåŒ–ï¼šè² å€¤/NaN/Infé™¤å» â†’ æ­£è¦åŒ–å¤±æ•—æ™‚ã¯ä¸€æ§˜åˆ†å¸ƒ
        weights = np.where(np.isfinite(weights) & (weights > 0), weights, 0.0)
        s = weights.sum()
        if not np.isfinite(s) or s <= 0:
            weights = None  # â†’ np.random.choice å´ã§ä¸€æ§˜åˆ†å¸ƒ
        else:
            weights = weights / s

        # 1) Diffusion ç”ŸæˆãŒä½¿ãˆã‚‹ãªã‚‰ãã‚Œã‚’å„ªå…ˆ
        if base_predictor is not None and getattr(base_predictor, "diffusion_model", None) is not None:
            try:
                from diffusion_module import sample_diffusion_ddpm
                trials = 0
                while len(out) < n_samples and trials < n_samples * 10:
                    trials += 1
                    x = sample_diffusion_ddpm(
                        base_predictor.diffusion_model,
                        getattr(base_predictor, "diffusion_betas", None),
                        getattr(base_predictor, "diffusion_alphas_cumprod", None),
                        dim=37,
                        num_samples=1,
                    )[0]
                    # ä¸Šä½7å€‹ã‚’æ¡ç”¨
                    nums = np.argsort(x)[-7:] + 1
                    nums = _ensure_valid(nums.tolist(), self.cfg.low, self.cfg.high)
                    if constraint_score(nums, self.cfg) >= accept_threshold:
                        out.append(nums)
            except Exception:
                pass

        # 2) Diffusion ãŒä½¿ãˆãªã„ï¼è¶³ã‚Šãªã„å ´åˆã¯ç¢ºç‡ã‚µãƒ³ãƒ—ãƒ«
        while len(out) < n_samples:
            cand = list(np.random.choice(pool, size=7, replace=False, p=weights)) if weights is not None else list(np.random.choice(pool, size=7, replace=False))
            cand = _ensure_valid(cand, self.cfg.low, self.cfg.high)
            if constraint_score(cand, self.cfg) >= accept_threshold:
                out.append(cand)
        return out


# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
# é™ç•Œçªç ´ Predictorï¼ˆãƒ¡ã‚¤ãƒ³ï¼‰
# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
class LimitBreakPredictor:
    def __init__(self, cfg: Optional[ConstraintConfig] = None):
        self.cfg = cfg or ConstraintConfig()
        self.base: Optional[LotoPredictor] = None
        self._init_base()
        self.sampler = ConditionalSampler(self.cfg)
        self.engine = EvolutionEngine(self.cfg)

    def _init_base(self):
        try:
            # å…¥åŠ›æ¬¡å…ƒã¯å‘¼ã³å‡ºã—æ™‚ã«æ±ºå®šã™ã‚‹ãŸã‚ãƒ€ãƒŸãƒ¼ã§åˆæœŸåŒ– â†’ äºˆæ¸¬å‰ã«ç½®ãæ›ãˆ
            self.base = LotoPredictor(input_size=10, hidden_size=128, output_size=7)  # type: ignore
        except Exception:
            self.base = None

    # â€”â€”â€” ãƒ¡ã‚¤ãƒ³ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ â€”â€”â€”
    def limit_break_predict(
        self,
        latest_data: pd.DataFrame,
        n_out: int = 50,
        ga_generations: int = 42,
        ga_pop_size: int = 160,
        sampler_n: int = 120,
    ) -> List[PredWithScore]:
        """æœ€çµ‚çš„ã« n_out ä»¶ã®ï¼ˆæ•°å­—, ä¿¡é ¼åº¦ï¼‰ã‚’è¿”ã™ã€‚"""
        set_global_seed(20250819)

        # æœªæ¥ãƒªãƒ¼ã‚¯ã‚’é¿ã‘ã€å­¦ç¿’/ç‰¹å¾´é‡ç”¨ã®å±¥æ­´ã‚’ä½œæˆ
        latest_data = latest_data.copy()
        latest_data["æŠ½ã›ã‚“æ—¥"] = pd.to_datetime(latest_data["æŠ½ã›ã‚“æ—¥"], errors="coerce")
        target_date = latest_data["æŠ½ã›ã‚“æ—¥"].max()
        history_df = latest_data[latest_data["æŠ½ã›ã‚“æ—¥"] < target_date]
        if history_df.empty:
            history_df = latest_data.iloc[:-1].copy()

        # ãƒ™ãƒ¼ã‚¹äºˆæ¸¬å€™è£œï¼ˆå­˜åœ¨ã™ã‚Œã°ï¼‰
        seed_candidates: List[NumberSet] = []
        if self.base is not None:
            try:
                # å…¥åŠ›æ¬¡å…ƒã‚’åˆã‚ã›ã‚‹ãŸã‚ä¸€åº¦å‰å‡¦ç†
                X, _, _ = preprocess_data(latest_data)
                input_size = X.shape[1] if X is not None and hasattr(X, "shape") else 10
                # base ã®å…¥å‡ºåŠ›ã‚’ä¸Šæ›¸ãåˆæœŸåŒ–ï¼ˆå®‰å…¨ï¼‰
                self.base = LotoPredictor(input_size=input_size, hidden_size=128, output_size=7)  # type: ignore
                preds, confs = self.base.predict(latest_data, num_candidates=120)
                if preds is not None:
                    seed_candidates = [
                        _ensure_valid(p, self.cfg.low, self.cfg.high) for p in preds
                    ]
            except Exception:
                traceback.print_exc()

        # æ¡ä»¶ä»˜ãã‚µãƒ³ãƒ—ãƒ©ãƒ¼ã§å¼·åŒ–ï¼ˆDiffusion/GAN åˆ©ç”¨ or ç¢ºç‡ã‚µãƒ³ãƒ—ãƒ«ï¼‰
        cond_samples = self.sampler.sample_with_constraints(
            base_predictor=self.base,
            hist_df=history_df,
            n_samples=sampler_n,
            accept_threshold=0.75,
        )

        seed_all = seed_candidates + cond_samples

        # é€²åŒ–æ¢ç´¢
        evolved = self.engine.search(
            seed_population=seed_all,
            hist_df=history_df,
            generations=ga_generations,
            pop_size=ga_pop_size,
            elite=max(ga_pop_size // 12, 8),
        )

        # æœ€çµ‚ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°
        pair_freq, triple_freq = pair_triple_frequencies(history_df)
        scored: List[PredWithScore] = []
        for c in evolved:
            cscore = constraint_score(c, self.cfg)
            co = cooccurrence_score(c, pair_freq, triple_freq)
            final = 0.6 * cscore + 0.4 * co
            # ä¿¡é ¼åº¦ 0.75ã€œ1.15 ã«å°„å½±
            conf = 0.75 + 0.40 * final
            scored.append((c, float(conf)))

        # åŒä¸€å€™è£œã®é‡è¤‡ã‚’é™¤å»
        uniq: Dict[Tuple[int, ...], float] = {}
        for nums, conf in scored:
            key = tuple(nums)
            if key not in uniq:
                uniq[key] = conf
            else:
                uniq[key] = max(uniq[key], conf)

        final = sorted(uniq.items(), key=lambda x: x[1], reverse=True)[:n_out]
        return [ (list(k), v) for k, v in final ]

    def save_predictions(self, predictions: List[PredWithScore], drawing_date: str, filename: str = "loto7_predictions.csv"):
        save_predictions_to_csv(predictions, drawing_date, filename=filename)


# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
# CLI ã‚¨ãƒ³ãƒˆãƒª
# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
if __name__ == "__main__":
    import asyncio

    def _get_latest_date_fallback(df: pd.DataFrame) -> str:
        d = pd.to_datetime(df["æŠ½ã›ã‚“æ—¥"], errors="coerce").max()
        return (d + pd.Timedelta(days=7)).strftime("%Y-%m-%d") if pd.notna(d) else pd.Timestamp.today().strftime("%Y-%m-%d")

    try:
        data = pd.read_csv("loto7.csv", encoding="utf-8-sig")
        # ãƒªã‚¹ãƒˆæ–‡å­—åˆ—ã‚’é…åˆ—ã«
        def _to_list(x):
            if isinstance(x, list):
                return x
            if isinstance(x, str):
                x = x.strip("[]").replace("'", "").replace('"', "")
                arr = [int(t) for t in x.split() if t.isdigit()]
                if len(arr) == 7:
                    return arr
            return []
        data["æœ¬æ•°å­—"] = data["æœ¬æ•°å­—"].apply(_to_list)
        data["æŠ½ã›ã‚“æ—¥"] = pd.to_datetime(data["æŠ½ã›ã‚“æ—¥"], errors="coerce")
    except Exception as e:
        print(f"[ERROR] loto7.csv ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
        raise SystemExit(1)

    # å…¬å¼ã‚µã‚¤ãƒˆã‹ã‚‰æŠ½ã›ã‚“æ—¥ã‚’å–ã‚Œã‚‹ç’°å¢ƒãªã‚‰ä½¿ç”¨ï¼ˆå¤±æ•—æ™‚ã¯ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼‰
    draw_date = None
    try:
        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)
        dates = loop.run_until_complete(get_latest_drawing_dates())
        if dates:
            draw_date = str(dates[0])
    except Exception:
        draw_date = None
    if not draw_date:
        draw_date = _get_latest_date_fallback(data)

    print(f"[INFO] äºˆæ¸¬å¯¾è±¡æŠ½ã›ã‚“æ—¥: {draw_date}")

    lbp = LimitBreakPredictor()
    preds = lbp.limit_break_predict(data.tail(50), n_out=50)

    print("=== é™ç•Œçªç ´ äºˆæ¸¬ï¼ˆä¸Šä½5ä»¶ï¼‰ ===")
    for i, (nums, conf) in enumerate(preds[:5], 1):
        print(f"#{i}: {nums}  ä¿¡é ¼åº¦={conf:.3f}")

    lbp.save_predictions(preds, draw_date)
    print("[DONE] äºˆæ¸¬ã‚’ CSV ã«ä¿å­˜ã—ã¾ã—ãŸ â†’ loto7_predictions.csv")


# =============================================================
# ğŸ”§ è¿½åŠ æ©Ÿèƒ½: æ¬ æå›ã®ä¸€æ‹¬äºˆæ¸¬ï¼ˆä¸Šæ›¸ãã§ã¯ãªãè¿½è¨˜ä¿å­˜ï¼‰
# =============================================================
def _make_prediction_row(preds, drawing_date: str):
    row = {"æŠ½ã›ã‚“æ—¥": drawing_date}
    for i, (nums, conf) in enumerate(preds[:5], 1):
        row[f"äºˆæ¸¬{i}"] = ", ".join(map(str, nums))
        row[f"ä¿¡é ¼åº¦{i}"] = round(float(conf), 3)
    return row

def _append_predictions_row(filename: str, row: dict):
    # æ—¢å­˜ãŒã‚ã‚Œã°èª­ã¿å–ã‚Šâ†’è¡Œã‚’è¿½åŠ â†’æŠ½ã›ã‚“æ—¥ã§é‡è¤‡æ’é™¤â†’æ—¥ä»˜æ˜‡é †ã§ä¿å­˜
    df_new = pd.DataFrame([row])
    if os.path.exists(filename):
        try:
            df_old = pd.read_csv(filename, encoding="utf-8-sig")
        except Exception:
            df_old = pd.read_csv(filename)
        # åˆ—ã®å–ã‚Šæƒãˆ
        cols = list(dict.fromkeys(df_old.columns.tolist() + df_new.columns.tolist()))
        df_old = df_old.reindex(columns=cols)
        df_new = df_new.reindex(columns=cols)
        df = pd.concat([df_old, df_new], ignore_index=True)
        # æŠ½ã›ã‚“æ—¥ã‚’æ­£è¦åŒ–ãƒ»é‡è¤‡æ’é™¤
        if "æŠ½ã›ã‚“æ—¥" in df.columns:
            df["æŠ½ã›ã‚“æ—¥"] = pd.to_datetime(df["æŠ½ã›ã‚“æ—¥"], errors="coerce")
            df = df.drop_duplicates(subset=["æŠ½ã›ã‚“æ—¥"], keep="first").sort_values("æŠ½ã›ã‚“æ—¥")
            df["æŠ½ã›ã‚“æ—¥"] = df["æŠ½ã›ã‚“æ—¥"].dt.strftime("%Y-%m-%d")
        df.to_csv(filename, index=False, encoding="utf-8-sig")
    else:
        df_new.to_csv(filename, index=False, encoding="utf-8-sig")

def backfill_predictions(self, full_data: pd.DataFrame, out_csv: str = "loto7_predictions.csv", n_out: int = 50):
    \"\"\"
    éå»1å›ç›®ã‹ã‚‰ç›´è¿‘ã¾ã§ã€ã¾ã ä¿å­˜ã•ã‚Œã¦ã„ãªã„å›ã®äºˆæ¸¬ã‚’é †æ¬¡ä½œæˆã—ã¦è¿½è¨˜ä¿å­˜ã™ã‚‹ã€‚
    - latest_data ã®å„æ—¥ä»˜ d ã«ã¤ã„ã¦ã€d ä»¥å‰ã®å±¥æ­´ã ã‘ã§äºˆæ¸¬ã—ã€ãã®æ—¥ã®è¡Œã‚’ out_csv ã«è¿½è¨˜ã€‚
    - æ—¢ã« out_csv ã«å­˜åœ¨ã™ã‚‹æ—¥ä»˜ã¯ã‚¹ã‚­ãƒƒãƒ—ã€‚
    - save_predictions_to_csv ã®ã€Œæ¯å›ä¸Šæ›¸ãã€å•é¡Œã‚’å›é¿ã™ã‚‹ãŸã‚ã€ã“ã“ã§è¿½è¨˜ä¿å­˜ã‚’å®Œçµã€‚
    \"\"\"
    # ãƒ‡ãƒ¼ã‚¿ã®æ—¥ä»˜ã‚’æ­£è¦åŒ–
    df = full_data.copy()
    df["æŠ½ã›ã‚“æ—¥"] = pd.to_datetime(df["æŠ½ã›ã‚“æ—¥"], errors="coerce")
    df = df.dropna(subset=["æŠ½ã›ã‚“æ—¥"]).sort_values("æŠ½ã›ã‚“æ—¥")

    # æ—¢å­˜ä¿å­˜ã®ã‚ã‚‹æ—¥ä»˜ã‚’åé›†
    existing_dates = set()
    if os.path.exists(out_csv):
        try:
            ex = pd.read_csv(out_csv, encoding="utf-8-sig")
        except Exception:
            ex = pd.read_csv(out_csv)
        if "æŠ½ã›ã‚“æ—¥" in ex.columns:
            existing_dates = set(pd.to_datetime(ex["æŠ½ã›ã‚“æ—¥"], errors="coerce").dropna().dt.date)

    # ã™ã¹ã¦ã®å¯¾è±¡æ—¥
    all_dates = [d.date() for d in df["æŠ½ã›ã‚“æ—¥"].unique()]

    # æœªä¿å­˜ã®ã¿ãƒ«ãƒ¼ãƒ—
    for d in all_dates:
        if d in existing_dates:
            continue
        # d å½“æ—¥ã®äºˆæ¸¬ã‚’ã€d ä»¥å‰ã®ã¿ã‚’ä½¿ã£ã¦ç”Ÿæˆ
        subset = df[df["æŠ½ã›ã‚“æ—¥"] <= pd.Timestamp(d)]
        preds = self.limit_break_predict(subset, n_out=n_out)
        row = _make_prediction_row(preds, drawing_date=str(d))
        _append_predictions_row(out_csv, row)
        print(f"[INFO] äºˆæ¸¬ã‚’è¿½è¨˜: {d}")

# ã‚¯ãƒ©ã‚¹ã«ãƒ¡ã‚½ãƒƒãƒ‰ã‚’ã‚¢ã‚¿ãƒƒãƒ
setattr(LimitBreakPredictor, "backfill_predictions", backfill_predictions)
